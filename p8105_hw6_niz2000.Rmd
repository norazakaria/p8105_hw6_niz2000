---
title: "p8105_hw6_niz2000"
author: "Nora Zakaria"
date: "11/25/2019"
output: github_document
---

## Load Tidyverse, Modelr, and Class Datasets

```{r}
library(tidyverse)
library(p8105.datasets)
library(modelr)
```


# Problem 1

## Load and Tidy the Birthweight Data

```{r warning=FALSE}
birthweight = 
  read_csv(file = "./data/birthweight.csv") %>%
  janitor::clean_names() %>%
  mutate(
    babysex = as.factor(babysex),
      babysex = fct_recode(babysex,
                  "male" = "1", "female" = "2"),
    frace = as.factor(frace),
      frace = fct_recode(frace,
                  "white" = "1", "black" = "2", "asian" = "3", 
                  "Puerto Rican" = "4", "Other" = "8", "Unknown" = "9"),
    malform = as.factor(malform),
      malform = fct_recode(malform,
                  "absent" = "0", "present" = "1"),             
    mrace = as.factor(mrace),
      mrace = fct_recode(mrace,
                  "white" = "1", "black" = "2", "asian" = "3", 
                  "Puerto Rican" = "4", "Other" = "8"))
birthweight
```

The four categorical variables in the dataset: babysex, frace, malform, and mrace, were converted from numeric to factor variables. These factors were also recoded in order for variable codes to be more descriptive. For example in the babysex variable, the factors now display "male" and "female," opposed to 1 and 2. There are `r nrow(birthweight)` observations and `r ncol(birthweight)` variables in the birthweight dataset.

### Test for Missing Values

After tidying, the missing_test dataframe was created to detect if there are any missing values in the dataset.

```{r warning=FALSE}
missing_test = birthweight %>%
  summarise_all((funs(sum(is.na(.))))) 
missing_test
```

As we see in the missing_test outputted table, there are 0 missing values in each of the variable columns, indicating that there are no missing values in the birthweight dataset.


## Regression Model for Birthweight

In this linear regression model for the birthweight (bwt) outcome, predictors include mother's pre-pregnancy BMI (ppbmi), mother’s weight gain during pregnancy in pounds (wtgain), mother's age at delivery in years (momage), the number of live births prior to this pregnancy (parity), and the average number of cigarettes smoked per day during pregnancy (smoken). These variables were selected based on previous academic literature findings on the factors that underly birthweight. In addition to mother's starting weight, weight gain during preganancy, and age, birth order and behavioral factors such as smoking all contribute to the birthweight of a newborn. 

```{r Fit Linear Model}
fit = lm(bwt ~ ppbmi + wtgain + momage + parity + smoken, data = birthweight)
fit

fit_summary_table = fit %>%
  broom::tidy() %>%
  knitr::kable(digits = 3, format = 'pandoc', caption = "Fit Linear Model Statistics") 
fit_summary_table
```

The linear model summary table provides the regression coefficients, standard error, test statistic, and p-value for all predictors in our model. All p-values were less than 0.05, apart from the "parity" variable, therefore "parity" is the only predictor in our model that is not statistically significant. Additionally, our regression coefficients for "parity" and "smoken" are negative, therefore demonstrating a negative linear relationship between the predictor and our birthweight outcome, with the remaining variables demonstrating a positive linear association. 


## Plot of Model Residuals and Fitted Values

```{r Model Plot}
modelr::add_predictions(birthweight, fit)
modelr::add_residuals(birthweight, fit)

birthweight %>%
  modelr::add_residuals(fit) %>%
  modelr::add_predictions(fit) %>%
  ggplot(aes(x = pred, y = resid)) +
    geom_point(aes(color = "viridis"), show.legend = FALSE) +
    labs(
      title = "Model Residuals Against Fitted Values",
      x = "Fitted Values",
      y = "Residuals")  +
    viridis::scale_color_viridis(discrete = TRUE) 
```

The scatterplot of residuals against fitted values is concentrated around fitted values from 2800 to 33000, and residual values from -1000 to 1000. ADD DESCRIPTIONS


## Comparing Fit Models

Next, the "fit" model will be compared to two additional models:

* The "main_effects_fit" model, including length at birth and gestational age as predictors; and
* The "interaction_fit" model, including head circumference, length at birth, sex, and all interacting terms as predictors.


### Predictors: Length at Birth and Gestational Age Main Effects

```{r Main_Effects_Fit Model}
main_effects_fit = lm(bwt ~ blength + gaweeks, data = birthweight)
main_effects_fit 
```

As there are no interaction terms, the length_age_fit regression model outputs an intercept, and two coefficients for each predictor.


### Predictors: Head Circumference, Length, Sex, and All Interacting Terms

```{r Interaction_Fit Model}
interaction_fit = lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex + 
  blength*babysex + bhead*blength*babysex, data = birthweight)
interaction_fit
```

As there are interaction terms, the interaction_terms_fit regression model outputs an intercept, and seven coefficients, three for each predictor, three for interaction terms between two predictors, and one coefficient for the interaction term between all three predictors.


### Comparing Cross-Validated Prediction Errors

In order to compare the "fit," "main_effects_fit," and "interaction_fit" model, cross-validation will be emplored. Cross validation provides a way to compare the predictive performance of competing methods.

```{r}
cv_df = 
  crossv_mc(birthweight, 100) %>%
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))
```


```{r Cross Validation}
cv_df = cv_df %>%
  mutate(
    fit = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
    main_effects_fit  = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
    interaction_fit = map(train, ~lm(bwt ~ bhead + blength + babysex + bhead*blength + 
        bhead*babysex + blength*babysex + bhead*blength*babysex, data = birthweight))) %>%
  mutate(
    rmse_fit = map2_dbl(fit, test, ~rmse(model = .x, data = .y)),
    rmse_main_effects = map2_dbl(main_effects_fit, test, ~rmse(model = .x, data = .y)),
    rmse_interaction = map2_dbl(interaction_fit, test, ~rmse(model = .x, data = .y)))
 
cv_df %>%
  select(starts_with("rmse")) %>%
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse",
    names_prefix = "rsme_") %>%
  mutate(model = fct_inorder(model)) %>%
  ggplot(aes(x = model, y = rmse, color = model)) +
    geom_violin() +
    labs(
      title = "Cross-Validated Prediction Errors",
      x = "Model",
      y = "RMSE") +
    viridis::scale_color_viridis(discrete = TRUE) 
```

Make this comparison in terms of the cross-validated prediction error; use crossv_mc and functions in purrr as appropriate. ADD DESCRIPTION.


# Problem 2

## Load 2017 Central Park NOAA Weather Data

```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
weather_df
```

There are `r nrow(weather_df)` observations and `r ncol(weather_df)` variables in the NOAA weather dataset for Central Park. Key variables for subsequent analyses include "tmin" and "tmax."


## Central Park Weather Bootstrap Data Frame

```{r Weather Bootstrap}
weather_bootstrap = weather_df %>%
  modelr::bootstrap(n = 5000) %>%
  mutate(
    models = map(strap, ~ lm(tmax ~ tmin, data = .x)))
 weather_bootstrap
```

The resulting weather_bootstrap dataframe consists of 5,000 bootstrap samples. The underlying simple linear regression model displays "tmax" as the response, and "tmin" as the predictor of interest.


## Distribution of log(β̂ 0∗β̂ 1)

```{r Log(Beta0*Beta1) Plot}
logbeta_plot = weather_bootstrap %>%
  mutate(results = map(models, broom::tidy)) %>%
  select(results) %>%
  unnest(results) %>%
  select(term, estimate) %>%
  pivot_wider(
    names_from = "term",
    values_from = "estimate") %>%
  unnest() %>%
  janitor::clean_names() %>%
  mutate(intercept_beta1 = intercept*tmin,
         log_intercept_beta1 = log(intercept_beta1)) %>%
  ggplot(aes(x = log_intercept_beta1)) +
    geom_density() +
    labs(
      title = "Distribution of Beta0*Beta1",
      x = "Log(Beta0*Beta1)",
      y = "Density") +
    viridis::scale_color_viridis(discrete = TRUE) +
    theme(plot.title = element_text(hjust = 0.5))
logbeta_plot
```

ADD DESCRIPTION

### 95% CI of log(β̂ 0∗β̂ 1)

```{r warning=FALSE}
weather_bootstrap %>%
  mutate(results = map(models, broom::tidy)) %>%
  select(results) %>%
  unnest(results) %>%
  select(term, estimate) %>%
  pivot_wider(
    names_from = "term",
    values_from = "estimate") %>%
  unnest() %>%
  janitor::clean_names() %>%
  mutate(intercept_beta1 = intercept*tmin,
    log_intercept_beta1 = log(intercept_beta1)) %>%
  pull(log_intercept_beta1) %>%
  as.vector() %>%
  quantile(probs = c(0.025, 0.975), na.rm = TRUE)
```

The 95% confidence interval for the  log(β̂ 0∗β̂ 1) is (1.97, 2.06).


## Distribution of r̂ 2

```{r R^2 Plot}
r_squared_plot = weather_bootstrap %>%
  mutate(results = map(models, broom::glance)) %>%
  select(results) %>%
  unnest(results) %>%
  ggplot(aes(x = r.squared)) +
    geom_density() +
    labs(
      title = "Distribution of R^2",
      x = "R^2",
      y = "Density") +
    viridis::scale_color_viridis(discrete = TRUE) +
    theme(plot.title = element_text(hjust = 0.5))
r_squared_plot
```

ADD DESCRIPTION

### 95% CI of r̂ 2

```{r}
weather_bootstrap %>%
  mutate(
    results = map(models, broom::glance)) %>%
  select(results) %>%
  unnest(results) %>%
  pull(r.squared) %>%
  as.vector() %>%
  quantile(probs = c(0.025, 0.975), na.rm = TRUE)
```

The 95% confidence interval for the r.squared value is (0.89, 0.93).
